{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "t9-pY0-Bvt53",
        "hIl3Rm1-taTD",
        "P6W08gMJtaEx",
        "C7ORFhjg0dnl"
      ],
      "authorship_tag": "ABX9TyMJsei8IH4bKmbxSdfAd0S1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yurifillippo/dataEngineer/blob/main/Engenharia_de_Dados_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9-pY0-Bvt53"
      },
      "source": [
        "# **MYSQL**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrwMql2xw38g"
      },
      "source": [
        "Acessar Mysql (-u usuario, -p senha)\n",
        "```\n",
        "mysql -u root -pcloudera;\n",
        "```\n",
        "\n",
        "Ver banco de dados dentro do mysql\n",
        "```\n",
        "show databases;\n",
        "```\n",
        "\n",
        "Mudar banco de dados\n",
        "```\n",
        "use retail_db;\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIl3Rm1-taTD"
      },
      "source": [
        "# **Sqoop**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WTiSZELtaMP"
      },
      "source": [
        "Listar banco de dados (passar a string de conexão (JDBC), nome de user e senha\n",
        "```\n",
        "sqoop list-databases --connect jdbc:mysql://localhost --username root --password cloudera \n",
        "```\n",
        "\n",
        "Listar tabelas (Informar também o nome do banco)\n",
        "```\n",
        "sqoop list-tables --connect jdbc:mysql://localhost/retail_db --username root --password cloudera \n",
        "```\n",
        "\n",
        "Importar dados (Informar a tabela)\n",
        "```\n",
        "sqoop import -connect jdbc:mysql://localhost/retail_db --table customers --username root --password cloudera\n",
        "```\n",
        "\n",
        "Verificar se jdbc está instalado\n",
        "```\n",
        "cd/var/lib/sqoop\n",
        "```\n",
        "\n",
        "Apagar pasta no cloudera\n",
        "```\n",
        "sudo hdfs dfs -rm -r /user/cloudera/departments\n",
        "```\n",
        "\n",
        "Verificar se os dados estão na raiz do hdfs\n",
        "```\n",
        "sudo hdfs dfs -ls /\n",
        "sudo hdfs dfs -ls /user\n",
        "sudo hdfs dfs -ls /user/cloudera\n",
        "```\n",
        "\n",
        "Abrir arquivo pasta do arquivo criado\n",
        "```\n",
        "sudo hdfs dfs -ls /user/cloudera/customers\n",
        "```\n",
        "\n",
        "Abrir arquivo-->>>VERIFICAR\n",
        "```\n",
        "sudo hdfs dfs -cat /user/cloudera/departments/part-m-00001\n",
        "```\n",
        "\n",
        "Importar todas tabelas\n",
        "```\n",
        "sqoop import-all-tables --connect jdbc:mysql://localhost/retail_db --username root --password cloudera --m 1\n",
        "```\n",
        "\n",
        "Mudar quantidade de processos \n",
        "```\n",
        "--m 1 (Um processo para cada tabela)\n",
        "--m 2 (Divide em dois processos)\n",
        "```\n",
        "\n",
        "Buscar tabelas incrementais (INSERT)\n",
        "```\n",
        "sqoop import --connect jdbc:mysql://localhost/retail_db --table categories --username root --password cloudera --check-column category_id --incremental append --last-value 59\n",
        "```\n",
        "\n",
        "Buscar tabela onde entradas tiveram alguma atualização (UPDATE)\n",
        "```\n",
        "sqoop import --connect jdbc:mysql://localhost/retail_db --table orders --username root --password cloudera --check-column order_date --incremental lastmodified --last-value 2014-07-24 --merge-key order_id\n",
        "```\n",
        "\n",
        "Ver arquivo na pasta\n",
        "```\n",
        "hdfs dfs -get /user/cloudera/orders/part-r-00000 /home/cloudera/part-r-00000.txt\n",
        "```\n",
        "\n",
        "Abrir arquivo\n",
        "```\n",
        "gedit part-r-00000.txt\n",
        "```\n",
        "\n",
        "Apagar tudo da pasta \n",
        "```\n",
        "sudo hdfs dfs -rm -r /user/cloudera/*\n",
        "```\n",
        "\n",
        "### JOBS SQOOP\n",
        "\n",
        "Ciar um job (Salvar senha, nome do job)\n",
        "\n",
        "```\n",
        "sqoop job -D sqoop.metastore.client.record.password=true --create categories -- import --connect jdbc:mysql://localhost/retail_db --table categories --username root --password cloudera --check-column category_id \n",
        "--incremental append --last-value 0\n",
        "```\n",
        "\n",
        "Excluir job\n",
        "```\n",
        "sqoop job --delete categories\n",
        "```\n",
        "\n",
        "Ver job\n",
        "```\n",
        "sqoop job --show categories\n",
        "```\n",
        "\n",
        "Executar Job\n",
        "```\n",
        "sqoop job --exec categories\n",
        "```\n",
        "\n",
        "Ver pasta e abrir arquivo\n",
        "```\n",
        "hdfs dfs -ls /user/cloudera/categories/\n",
        "hdfs dfs -cat /user/cloudera/categories/part-m-00003\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6W08gMJtaEx"
      },
      "source": [
        "# **HDFS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZbhsLUEyrBl"
      },
      "source": [
        "Baixar Arquivo de palavras para fazer o mapreduce\n",
        "\n",
        "```\n",
        "wget www.datascientist.com.br/bigdata/pesquisa.txt\n",
        "```\n",
        "\n",
        "Download do script em Java para MapReduce\n",
        "```\n",
        "wget www.datascientist.com.br/bigdata/WordCount.java\n",
        "```\n",
        "\n",
        "Abrir arquivo\n",
        "```\n",
        "cat pesquisa.txt\n",
        "```\n",
        "\n",
        "Abrir arquivo como editor de texto\n",
        "```\n",
        "gedit pesquisa.txt\n",
        "```\n",
        "\n",
        "Abrir arquivo como editor de texto\n",
        "```\n",
        "gedit WordCount.java\n",
        "```\n",
        "\n",
        "Ver pastas no HDFS\n",
        "```\n",
        "sudo hdfs dfs -ls /\n",
        "```\n",
        "\n",
        "Criar pasta no HDFS\n",
        "```\n",
        "sudo hdfs dfs -mkdir /contar\n",
        "```\n",
        "\n",
        "Copiar arquivo do Linux para HDFS (Onde ele esta/ Para onde será copiado\n",
        "```\n",
        "sudo hdfs dfs -put pesquisa.txt /contar/pesquisa.txt\n",
        "```\n",
        "\n",
        "Ver o que tem dentro da pasta\n",
        "```\n",
        "sudo hdfs dfs -ls /contar/\n",
        "```\n",
        "\n",
        "Compilar programa Java\n",
        ">Abrir Eclipse\n",
        "\n",
        ">Ir em: File>New>Java Project\n",
        "\n",
        ">Colocar nome no projeto > Finalizar\n",
        "\n",
        "###Importar arquivo com script\n",
        "\n",
        "> File>Import\n",
        "\n",
        "> Selecionar: File system > Next > Selecionar pasta do arquivo > Selecionar arquivo > Info folder > Selecionar em Into Folder o nome do projeto > Finalizar\n",
        "\n",
        "Criar pacote\n",
        "\n",
        ">Botão direito no projeto > New > Package > \"PackageDemo\" (exemplo de nome) > Finalizar\n",
        "\n",
        ">Selecionar Script para dentro do Package criado\n",
        "\n",
        "###Importar pacotes\n",
        "\n",
        "> Botão direito no projeto > Build Path > Add External Archives\n",
        "> Selecionar pacotes dentro de \n",
        "\n",
        "usr/lib/hadoop/hadoop-commoon-2.6.0-cdh5.13.0.jar\n",
        "\n",
        "usr/lib/hadoop-0.20-mapreduce/lib/commons-cli-1.2.jar\n",
        "\n",
        "usr/lib/hadoop-0.20-mapreduce/hadoop-core-2.6.0-mr1-cdh5.13.0.jar\n",
        "\n",
        ">Nenhum arquivo do cod. deve ser manter sublinhado\n",
        "\n",
        "###Compilar script\n",
        ">Botão direito no projeto > Export > Selecionar Java > Jar File > Next >\n",
        "\n",
        ">Em browser selecionar cloudera e alterar nome do arquivo:\n",
        "/home/cloudera/MRProgramaDemo.jar > Finalizar\n",
        "\n",
        ">No prompt - Abrir programa \"hadoop jar Nome_do_programa/nome_do_pacote.classe/ Informar_local_e_nome_do_arquivo_que_o_programa_irá_processar/ informar_endereço_para_resultado_do_processamento\"\n",
        "hadoop jar MRProgramaDemo.jar PackageDemo.WordCount /contar/pesquisa.txt /contar2\n",
        "\n",
        "Verificar arquivos gerados\n",
        "```\n",
        "sudo hdfs dfs -ls /contar2/\n",
        "```\n",
        "\n",
        "Abrir arquivo\n",
        "```\n",
        "sudo hdfs dfs -cat /contar2/part-r-00000\n",
        "```\n",
        "\n",
        "Retirar o arquivo do hdfs\n",
        "```\n",
        "sudo hdfs dfs -get /contar2/part-r-00000 /home/cloudera\n",
        "```\n",
        "\n",
        "Abrir arquivo como editor de texto\n",
        "```\n",
        "gedit part-r-00000]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7ORFhjg0dnl"
      },
      "source": [
        "# **HIVE**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42VmoTzs0nRY"
      },
      "source": [
        "Download de arquivos\n",
        "\n",
        "```\n",
        "wget www.datascientist.com.br/bigdata/clientes.csv\n",
        "wget www.datascientist.com.br/bigdata/despachantes.csv\n",
        "wget www.datascientist.com.br/bigdata/locacao.csv\n",
        "wget www.datascientist.com.br/bigdata/veiculos.csv\n",
        "```\n",
        "\n",
        "Criar pasta hdfs\n",
        "```\n",
        "hdfs dfs -mkdir /user/cloudera/locacao\n",
        "```\n",
        "\n",
        "Ver pasta\n",
        "```\n",
        "hdfs dfs -ls /user/cloudera/locacao/\n",
        "```\n",
        "\n",
        "Encaminhar arquivos para a pasta com formato csv\n",
        "```\n",
        "hdfs dfs -put *.csv /user/cloudera/locacao\n",
        "```\n",
        "\n",
        "###CONECTAR AO HIVE\n",
        "```\n",
        "beeline\n",
        "!connect jdbc:hive2://\n",
        "```\n",
        "\n",
        "Ver bancos de dados\n",
        "```\n",
        "show databases;\n",
        "```\n",
        "\n",
        "Criar banco de dados\n",
        "```\n",
        "create database retail_db;\n",
        "```\n",
        "\n",
        "Excluir banco de dados\n",
        "```\n",
        "drop database retail_db cascade;\n",
        "```\n",
        "\n",
        "Acessar banco de dados\n",
        "```\n",
        "use locacao\n",
        "```\n",
        "\n",
        "\n",
        "Criar tabelas\n",
        "```\n",
        "create external table clientes (idcliente int, cpf string, cnh string, validadecnh date, nome string, datacadastro date, datanascimento date, telefone string, status string) row format delimited fields terminated by ',' stored as textfile;\n",
        "```\n",
        "```\n",
        "create external table veiculos (idveiculo int, dataaquisicao date, ano int, modelo string, placa string, status string, diaria double) row format delimited fields terminated by ',' stored as textfile;\n",
        "```\n",
        "```\n",
        "create external table despachante (iddespachante int, nome string, status string, filial string) row format delimited fields terminated by ',' stored as textfile;\n",
        "```\n",
        "```\n",
        "create external table locacao (idlocacao int, idcliente int, iddespachante int, idveiculo int, datalocacao date, dataentrega date, total double) row format delimited fields terminated by ',' stored as textfile;\n",
        "```\n",
        "\n",
        "Criar schemas\n",
        "```\n",
        "LOAD DATA INPATH '/user/cloudera/locacao/clientes.csv' INTO TABLE CLIENTES;\n",
        "LOAD DATA INPATH '/user/cloudera/locacao/veiculos.csv' INTO TABLE veiculos;\n",
        "LOAD DATA INPATH '/user/cloudera/locacao/despachantes.csv' INTO TABLE despachante;\n",
        "LOAD DATA INPATH '/user/cloudera/locacao/locacao.csv' INTO TABLE locacao;\n",
        "```\n",
        "\n",
        "Saber mais detalhes sobre tabelas/banco de dados\n",
        "```\n",
        "describe clientes;\n",
        "describe formatted clientes;\n",
        "describe database locacao;\n",
        "```\n",
        "\n",
        "###DO SQOOP PARA O HIVE\n",
        "\n",
        "Criar banco de dados no Hive\n",
        "```\n",
        "create database retail_db;\n",
        "```\n",
        "\n",
        "Extrair dados do SQOOP (Comando sqoop)\n",
        "```\n",
        "sqoop import-all-tables --connect jdbc:mysql://localhost/retail_db --username root --password cloudera --hive-import --hive-overwrite --hive-database retail_db --create-hive-table --m 1\n",
        "```\n"
      ]
    }
  ]
}